# HarmonyHub_Emotional-Based-Music

The "HarmonyHub - Machine Learning Driven Emotion-Based Music Recommendations" project aims to redefine how users experience music by tailoring song recommendations to their emotions in real time. Combining real-time facial analysis with advanced machine learning models, HarmonyHub delivers personalized music that aligns with the user's emotional state. Unlike traditional systems that rely solely on past listening data or user preferences, HarmonyHub provides dynamic, immediate responses based on the userâ€™s mood in the moment. 
By leveraging facial landmark detection and emotion recognition, the system detects emotional cues from the user's facial expressions, such as happiness, sadness, or surprise. These cues are then used to recommend songs that resonate with their current mood. The system also incorporates additional personalization layers, such as allowing users to specify preferences like language and favorite artists, which further refine the recommendations. 
HarmonyHub represents a major advancement in the field of personalized music recommendation, creating a more empathetic and emotionally aware interaction between the system and the user. Whether someone needs an uplifting song after a tough day or something calming for focus, HarmonyHub adjusts to their emotional needs, pushing the boundaries of emotional intelligence and music curation.
